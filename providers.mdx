---
title: "api providers"
description: "get your free api key and start renaming layers"
icon: "key"
---

— cerebras (recommended)

cerebras is the default provider because it offers:

- **free api access** — no credit card required
- **blazing fast inference** — 3,000+ tokens per second
- **powerful models** — including gpt-oss-120b with 128k context window

<Steps>
  <Step title="create a cerebras account">
    go to [cloud.cerebras.ai](https://cloud.cerebras.ai) and sign up for free.
  </Step>
  <Step title="generate an api key">
    once logged in, navigate to the api keys section and create a new key. copy it.
  </Step>
  <Step title="paste in layersense">
    open layersense settings → api tab → paste your key in the "api key" field.
  </Step>
  <Step title="select a model">
    recommended models:
    - `gpt-oss-120b` — best quality, 128k context, 3,000+ tok/s
    - `llama-3.3-70b` — balanced performance, 2,100 tok/s
    - `qwen-3-32b` — fast and efficient, 2,600 tok/s
  </Step>
</Steps>

<Note>
cerebras free tier has generous rate limits. if you hit them, the plugin automatically retries with delays.
</Note>

— google gemini (free)

google offers a generous free tier for gemini models.

<Steps>
  <Step title="get your api key">
    go to [aistudio.google.com](https://aistudio.google.com) and create an api key.
  </Step>
  <Step title="configure layersense">
    settings → api tab → provider: **google gemini** → paste your key.
  </Step>
  <Step title="select a model">
    - `gemini-3-pro` — newest, most intelligent (preview)
    - `gemini-2.5-flash` — best price-performance, 1M context
    - `gemini-2.5-pro` — advanced thinking model
  </Step>
</Steps>

— openrouter

openrouter aggregates multiple providers and offers some free models.

<Steps>
  <Step title="create an account">
    go to [openrouter.ai](https://openrouter.ai) and sign up.
  </Step>
  <Step title="get your api key">
    find your api key in the dashboard.
  </Step>
  <Step title="configure layersense">
    settings → api tab → provider: **openrouter** → paste your key.
  </Step>
  <Step title="use free models">
    look for models tagged `:free` like:
    - `mistralai/devstral-2512:free` — 123b coding specialist
    - `meta-llama/llama-3-8b-instruct:free` — balanced all-purpose
  </Step>
</Steps>

— local (lm studio)

run models on your own computer for complete privacy and no rate limits.

<Steps>
  <Step title="download lm studio">
    get it from [lmstudio.ai](https://lmstudio.ai) — available for windows, mac, and linux.
  </Step>
  <Step title="download a model">
    inside lm studio, search for and download a model. recommended:
    - qwen 2.5 (various sizes)
    - llama 3 8b
    - mistral 7b
  </Step>
  <Step title="start the local server">
    in lm studio, go to the "local server" tab and click start. the default endpoint is `http://127.0.0.1:1234/v1/chat/completions`.
  </Step>
  <Step title="configure layersense">
    settings → api tab → provider: **local (lm studio)** → verify the endpoint matches your lm studio server.
  </Step>
</Steps>

<Note>
local models require a decent gpu for fast inference. cpu-only works but is slower.
</Note>

— paid providers

if you already have api keys from paid providers:

| provider | setup | recommended models |
|----------|-------|-------------------|
| **openai** | paste your key, select provider "openai" | `gpt-5.1` (best for agents), `gpt-5-nano` (cheapest), `gpt-4.1-mini` |
| **anthropic** | paste your key, select provider "anthropic" | `claude-sonnet-4-5` (best balance), `claude-haiku-4-5` (fastest), `claude-opus-4-5` (most capable) |

— which provider to choose?

| your situation | recommended provider |
|----------------|---------------------|
| just want it to work for free | **cerebras** with `gpt-oss-120b` (3,000+ tok/s) |
| need maximum privacy | **local** with lm studio |
| already have openai/anthropic keys | use your existing provider |
| want cutting-edge intelligence | **google gemini** with `gemini-3-pro` |
| want to try different models | **openrouter** for variety |
