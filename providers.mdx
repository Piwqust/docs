---
title: "API Providers"
description: "How to use the plugin 100% for free with Google Gemini, OpenRouter, Cerebras, or local LLMs"
icon: "key"
---

layersense is "bring your own key", meaning you are not locked into a subscription.

## Free Providers

<Info>
You don't need a credit card. Here is where to get free access:
</Info>

<Tabs>
  <Tab title="Google Gemini (Recommended)">
    **Get Key:** [aistudio.google.com](https://aistudio.google.com/)
    
    **Models:**
    - `gemini-1.5-flash` (fastest)
    - `gemini-2.0-flash-exp`
    
    <Note>High rate limits, perfect for heavy usage.</Note>
  </Tab>
  
  <Tab title="Cerebras">
    **Get Key:** [cloud.cerebras.ai](https://cloud.cerebras.ai/)
    
    **Model:** `llama3.1-70b`
    
    <Note>Incredibly fast, though context may be limited during peak traffic.</Note>
  </Tab>
  
  <Tab title="OpenRouter">
    **Get Key:** [openrouter.ai](https://openrouter.ai/)
    
    **Free Models:**
    - `mistralai/mistral-7b-instruct:free`
    - `meta-llama/llama-3-8b-instruct:free`
  </Tab>
  
  <Tab title="Local LLMs">
    **Download:** [lmstudio.ai](https://lmstudio.ai/)
    
    **Setup:**
    1. Install LM Studio
    2. Load a model (e.g., `Qwen 2.5` or `Llama 3.2`)
    3. Start the **Local Inference Server**
    4. In layersense, select **Local (LM Studio)**
    
    <Check>Zero data leaves your computer.</Check>
  </Tab>
</Tabs>

## Commercial Providers

If you have a key, we also support:

| Provider | Models |
|----------|--------|
| **OpenAI** | `gpt-4o`, `gpt-4o-mini` |
| **Anthropic** | `claude-3-5-sonnet`, `claude-3-haiku` |

## Settings Configuration

| Setting | Description |
|---------|-------------|
| **Model Selection** | Manually type any model ID (e.g., `gpt-4o`) |
| **Temperature** | Controls "creativity". Lower (0.1) is more consistent; higher (0.7+) is more random |
| **Export/Import** | Save your settings to a JSON file to share with teammates |
